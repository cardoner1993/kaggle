{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":["import spacy\n","import glob\n","import os\n","import yaml\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import StratifiedKFold\n","from tqdm import tqdm\n","from tqdm import tqdm\n","from pathlib import Path\n","import random\n","import numpy as np\n","\n","from termcolor import colored\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from transformers import BertTokenizerFast, BertForSequenceClassification, AdamW, TFBertModel\n","from transformers import get_linear_schedule_with_warmup\n","from sklearn.metrics import mean_squared_error\n","\n","\n","import torch\n","# from GPUtil import showUtilization as gpu_usage\n","from numba import cuda\n","\n","def free_gpu_cache():\n","    print(\"Initial GPU Usage\")\n","    gpu_usage()                             \n","\n","    torch.cuda.empty_cache()\n","\n","    cuda.select_device(0)\n","    cuda.close()\n","    cuda.select_device(0)\n","\n","    print(\"GPU Usage after emptying the cache\")\n","    gpu_usage()\n","\n","# free_gpu_cache()                \n","\n","if torch.cuda.is_available():        \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","else:\n","    print('No GPU available, please check.')\n","    device = torch.device(\"cpu\")\n","\n","\n"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-07T07:38:47.415077Z","iopub.execute_input":"2021-07-07T07:38:47.415403Z","iopub.status.idle":"2021-07-07T07:38:57.099831Z","shell.execute_reply.started":"2021-07-07T07:38:47.415331Z","shell.execute_reply":"2021-07-07T07:38:57.098869Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"There are 1 GPU(s) available.\nWe will use the GPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}]},{"cell_type":"code","source":["# !pip3 install pickle5"],"metadata":{"execution":{"iopub.status.busy":"2021-07-07T07:38:57.101234Z","iopub.execute_input":"2021-07-07T07:38:57.101638Z","iopub.status.idle":"2021-07-07T07:38:57.105457Z","shell.execute_reply.started":"2021-07-07T07:38:57.101581Z","shell.execute_reply":"2021-07-07T07:38:57.104581Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import logging\n","import numpy as np\n","import os\n","import pandas as pd\n","import pickle\n","import random\n","import re\n","import string\n","import sys\n","import time\n","\n","from pathlib import Path\n","import yaml\n","\n","from tqdm import tqdm\n","from functools import partial\n","from nltk.corpus import words, stopwords\n","\n","import tensorflow_addons as tfa\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential, save_model, load_model, model_from_yaml\n","from tensorflow.keras.layers import Conv1D, \\\n","    Flatten, \\\n","    GlobalMaxPooling1D, \\\n","    TimeDistributed, \\\n","    MaxPooling1D, \\\n","    Dense, \\\n","    Activation, \\\n","    ReLU, \\\n","    LSTM, \\\n","    GRU, \\\n","    SpatialDropout1D, \\\n","    Dropout, \\\n","    Bidirectional, \\\n","    Embedding, \\\n","    Add\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","from tensorflow.keras.layers import Layer, InputSpec\n","from datetime import datetime\n","\n","import torch\n","from numba import cuda\n","import gc\n","import tensorflow as tf\n","from tensorflow.python.keras import backend as K\n","\n","\n","random.seed(0)\n","np.random.seed(0)\n","\n","def free_gpu_cache():\n","    print(\"Initial GPU Usage\")\n","    gpu_usage()\n","\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","    # device = cuda.get_current_device()\n","    # device.reset()\n","\n","    # current_device = cuda.get_current_device().id\n","    # cuda.select_device(current_device)\n","    # cuda.close()\n","    # cuda.select_device(current_device)\n","\n","    print(\"GPU Usage after emptying the cache\")\n","    gpu_usage()\n","\n","\n","def config_gpu_growth():\n","    config = tf.compat.v1.ConfigProto()\n","    config.gpu_options.allow_growth = True\n","    sess = tf.compat.v1.Session(config=config)\n","    K.set_session(sess)\n","\n","    return sess\n","\n","\n","def close_sess_keras(sess):\n","    sess.close()\n","    tf.keras.backend.clear_session()\n","# free_gpu_cache()\n","\n","punctuation = string.punctuation.replace(\"@\", \"\").replace(\"+\", \"\").replace(\"-\", \"\").replace(\"_\", \"\")\n","stop_words = set(stopwords.words('english'))\n","\n","\n","def timing_val(func):\n","    def wrapper(*arg, **kw):\n","        t1 = time.time()\n","        res = func(*arg, **kw)\n","        t2 = time.time()\n","        # print(f\"\\nFunc {func.__name__} took {(t2 - t1)}\")\n","        return res\n","\n","    return wrapper\n","\n","\n","class ResidualBlock1D(Layer):\n","    def __init__(self, channels_in, kernel, **kwargs):\n","        super(ResidualBlock1D, self).__init__(**kwargs)\n","        self.channels_in = channels_in\n","        self.kernel = kernel\n","\n","        self.conv1 = Conv1D(self.channels_in,\n","                            self.kernel,\n","                            padding='same',\n","                            activation='relu')\n","        self.conv2 = Conv1D(self.channels_in,\n","                            self.kernel,\n","                            padding='same')\n","        self.activation = Activation('relu')\n","\n","    def call(self, x):\n","        y = x\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = Add()([x, y])\n","        x = self.activation(x)\n","        return x\n","\n","    def get_config(self):\n","        config = super().get_config().copy()\n","        config.update({\n","            'channels_in': self.channels_in,\n","            'kernel': self.kernel,\n","        })\n","        return config\n","\n","\n","class DNN:\n","    def __init__(\n","            self,\n","            backbone='conv',  # New option TEST_CLIT\n","            charlevel=False,\n","            use_glove=True,\n","            preprocess_data=False,\n","            logger=None,\n","            batch_size=64,\n","            max_vocab=10000,\n","            max_len=8192,\n","            embedding_mat_columns=50,\n","            epochs=200\n","    ):\n","\n","        self.backbone = backbone\n","        self.charlevel = charlevel\n","        self.use_glove = use_glove\n","        self.preprocess_data = preprocess_data\n","\n","        self.OOV_TOK = '<OOV>'\n","        self.PADDING_TYPE = 'post'\n","        self.TRUNCATE_TYPE = 'pre'  # 'post'\n","        self.batch_size = batch_size\n","        self.max_vocab = max_vocab\n","        self.max_len = max_len\n","        self.embedding_mat_columns = embedding_mat_columns\n","\n","        self.__model = None\n","        self.res = list()\n","        self.is_trained = False\n","\n","        self.logger = logger\n","        self.epochs = epochs\n","\n","        self.augment = False\n","\n","        if self.charlevel and self.use_glove:\n","            if logger:\n","                logger.warning('charlevel and use_glove both set to true. use_glove will be ignored.')\n","\n","    @property\n","    def model(self):\n","        return self.__model\n","\n","    @model.setter\n","    def model(self, value):\n","        self.__model = value\n","\n","    @staticmethod\n","    def clean_text(txt):\n","        return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower()).strip()\n","\n","    def preprocess_texts(self, texts, tokens=[]):\n","        preprocessed_texts = []\n","        additional_tokens = []\n","\n","        for text in texts:\n","            if self.preprocess_data:\n","                text = self.clean_text(text)\n","\n","            preprocessed_texts.append(text)\n","\n","        return np.array(preprocessed_texts), tokens, np.array(additional_tokens)\n","\n","    def fit_tokenizer(self, texts):\n","        if isinstance(texts, str):\n","            texts = [texts]\n","        elif isinstance(texts, tuple):\n","            texts = list(texts)\n","        elif not isinstance(texts, (list, pd.core.series.Series, np.ndarray)):\n","            raise ValueError(\"The text must be a list of strings, a list of lists containing strings or a string\")\n","\n","        self.tokenizer.fit_on_texts(texts)\n","\n","    def sequence_padding(self, sequences):\n","        seqs = pad_sequences(sequences, maxlen=self.max_len, padding=self.PADDING_TYPE, truncating=self.TRUNCATE_TYPE)\n","        return seqs\n","\n","    def load_glove(self, additional_tokens=[]):\n","        embeddings_index = {}\n","        glove_path = f'../../data/glove.6B.{self.embedding_mat_columns}d.txt'  # Todo change it if running from MAIN\n","        f = open(glove_path)\n","        for line in f:\n","            values = line.split()\n","            word = values[0]\n","            coefs = np.asarray(values[1:], dtype='float32')\n","            embeddings_index[word] = coefs\n","        f.close()\n","        # print(len(embeddings_index))\n","\n","        # embedding_matrix = np.zeros((len(embeddings_index) + 2 + len(additional_tokens), self.embedding_mat_columns))\n","        embedding_matrix = np.random.randn(len(embeddings_index) + 2 + len(additional_tokens),\n","                                           self.embedding_mat_columns)\n","        w2i = {}\n","        for i, (word, embs) in enumerate(embeddings_index.items()):\n","            embedding_matrix[i] = embs\n","            w2i[word] = i\n","        i += 1\n","        w2i['<OOV>'] = i\n","\n","        if self.logger:\n","            self.logger.info(f'load_glove: {embedding_matrix.shape}, {len(w2i.keys())}')\n","        else:\n","            print('load_glove', embedding_matrix.shape, len(w2i.keys()))\n","\n","        return embeddings_index, w2i, embedding_matrix\n","\n","    def compute_output_shape(self, input_shape):\n","        return input_shape\n","\n","    def get_model(self, vocab_size, embedding_matrix=None):\n","\n","        model = Sequential()\n","        model.add(Embedding(\n","            vocab_size,\n","            self.embedding_mat_columns,\n","            embeddings_initializer=tf.keras.initializers.Constant(\n","                embedding_matrix) if embedding_matrix is not None else None\n","        ))\n","\n","        if self.backbone == 'LSTM':\n","            model.add(Bidirectional(LSTM(self.embedding_mat_columns)))\n","        elif self.backbone == 'GRU':\n","            model.add(Bidirectional(GRU(self.embedding_mat_columns)))\n","        elif self.backbone == 'CONV':\n","            model.add(Conv1D(512, 3, activation='relu'))\n","            model.add(ResidualBlock1D(512, 3))\n","            model.add(MaxPooling1D())\n","            model.add(Conv1D(256, 3, activation='relu'))\n","            model.add(ResidualBlock1D(256, 3))\n","            model.add(MaxPooling1D())\n","            model.add(Conv1D(128, 3, activation='relu'))\n","            model.add(ResidualBlock1D(128, 3))\n","            model.add(GlobalMaxPooling1D())\n","        elif self.backbone == 'DEMO':\n","            model.add(Conv1D(256, 3, activation='relu'))\n","            model.add(GlobalMaxPooling1D())\n","        elif self.backbone == 'TEST_CLIT':\n","            model.add(Conv1D(64, 5, padding='valid', kernel_initializer='normal', activation='relu'))\n","            model.add(MaxPooling1D(2))\n","            model.add(Conv1D(128, 5, padding='valid', kernel_initializer='normal', activation='relu'))\n","            model.add(MaxPooling1D(2))\n","            model.add(Conv1D(256, 5, padding='valid', kernel_initializer='normal', activation='relu'))\n","            model.add(Conv1D(512, 5, padding='valid', kernel_initializer='normal', activation='relu'))\n","            model.add(Conv1D(1024, 5, padding='valid', kernel_initializer='normal', activation='relu'))\n","            model.add(Conv1D(2048, 5, padding='valid', kernel_initializer='normal', activation='relu'))\n","            model.add(Conv1D(4098, 5, padding='valid', kernel_initializer='normal', activation='relu'))\n","            model.add(GlobalMaxPooling1D())\n","            model.add(Dense(120, kernel_initializer='normal', activation='relu'))\n","            model.add(Dense(240, kernel_initializer='normal', activation='relu'))\n","            model.add(Dense(480, kernel_initializer='normal', activation='relu'))\n","            model.add(Dense(980, kernel_initializer='normal', activation='relu'))\n","        else:\n","            raise NotImplementedError\n","\n","        model.add(Dense(1))\n","\n","        return model\n","\n","    def fit(self, X_train, y_train, out_path):\n","        X, y = X_train, y_train\n","\n","        if not Path(out_path).exists():\n","            os.makedirs(out_path)\n","\n","        X, self.tokens, additional_tokens = self.preprocess_texts(X)\n","\n","        embedding_matrix = None\n","        if self.charlevel:\n","            self.tokenizer = Tokenizer(oov_token=self.OOV_TOK, filters='', lower=False, char_level=True)\n","            self.fit_tokenizer(texts=X)\n","        else:\n","            self.tokenizer = Tokenizer(oov_token=self.OOV_TOK, lower=True,\n","                                       char_level=False)  # filters='<', lower=False,\n","\n","            if self.use_glove:\n","                _, w2i, embedding_matrix = self.load_glove(additional_tokens=additional_tokens)\n","                self.tokenizer.word_index = w2i\n","            else:\n","                self.fit_tokenizer(texts=X)\n","\n","        # sequences = np.array(self.tokenizer.texts_to_sequences(X))\n","        sequences = self.tokenizer.texts_to_sequences(X)\n","\n","        X = self.sequence_padding(sequences)\n","\n","        self.model = self.get_model(vocab_size=(len(self.tokenizer.word_index) + 1), embedding_matrix=embedding_matrix)\n","\n","        opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n","\n","        self.model.compile(loss='mean_squared_error', optimizer=opt, metrics=[tf.metrics.MeanSquaredError()])\n","\n","        self.model.summary()\n","\n","        es = EarlyStopping(\n","            monitor='val_mean_squared_error',\n","            mode='min',\n","            patience=20,\n","            verbose=1\n","        )\n","        lr_sch = ReduceLROnPlateau(\n","            monitor='val_mean_squared_error',\n","            mode='min',\n","            factor=0.1,\n","            patience=10,\n","            verbose=1,\n","            min_delta=0.001,\n","            cooldown=0,\n","            min_lr=1e-6,\n","        )\n","        ckpt = ModelCheckpoint(\n","            os.path.join(out_path, 'model.h5'),\n","            monitor='val_mean_squared_error',\n","            mode='min',\n","            verbose=1,\n","            save_best_only=True,\n","            save_weights_only=False,\n","            save_freq='epoch'\n","        )\n","\n","        try:\n","            # print(self.batch_size)\n","            self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, validation_split=0.2, verbose=1,\n","                           callbacks=[es, lr_sch, ckpt])\n","        except KeyboardInterrupt:\n","            print('Got KeyboardInterrupt. Stopping.')\n","\n","        self.is_trained = True\n","\n","    def predict_proba(self, X):\n","        assert self.is_trained, 'Model should be trained before inference.'\n","        if isinstance(X, str):\n","            X = [X]\n","\n","        if self.preprocess_texts:\n","            X, _, _ = self.preprocess_texts(X)\n","\n","        sequences = self.tokenizer.texts_to_sequences(X)\n","        padded = self.sequence_padding(sequences)\n","        preds = self.model.predict(padded)\n","\n","        return preds\n","\n","    def predict(self, X, return_proba=False):\n","        print(\"=====================\")\n","        assert self.is_trained, 'Model should be trained before inference.'\n","        print(X)\n","        proba = self.predict_proba(X)\n","        print(proba)\n","        preds = np.argmax(proba, axis=1)\n","\n","        if return_proba:\n","            return proba\n","        else:\n","            return preds\n","\n","    def save(self, path):\n","        if self.is_trained:\n","\n","            output_dir = Path(path)\n","            if not output_dir.exists():\n","                Path.mkdir(output_dir, parents=True, exist_ok=True)\n","\n","            # serialize model to YAML\n","            model_yaml = self.model.to_yaml()\n","            with open(output_dir / 'nn_model_config.yaml', 'w') as file:\n","                file.write(model_yaml)\n","            # serialize weights to HDF5\n","            self.model.save_weights(output_dir / \"model.h5\")\n","\n","            with open(output_dir / 'tokenizer3.pkl', 'wb') as file:\n","                pickle.dump(self.tokenizer, file, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","            # self.logger.info(f'Saved model to {output_dir}')\n","        else:\n","            pass\n","            # self.logger.warning('Cannot save the model. Train it first.')\n","\n","    def load(self, path):\n","        print(\"Loading model...\")\n","        output_dir = Path(path)\n","        \n","        print(\"Loading tokenizer\")\n","        with open(output_dir / 'tokenizer3.pkl', 'rb') as file:\n","            self.tokenizer = pickle.load(file)\n","        \n","        with open(output_dir / 'nn_model_config.yaml') as file:\n","            print(\"Reading...\")\n","            model_config = file.read()\n","        print(\"Model from yaml\")\n","        self.model = model_from_yaml(model_config, custom_objects={'ResidualBlock1D': ResidualBlock1D})\n","        print(\"Loading weights\")\n","        self.model.load_weights(output_dir / \"model.h5\")\n","        \n","        print(\"Done\")\n","\n","        self.is_trained = True\n","        \n"],"metadata":{"execution":{"iopub.status.busy":"2021-07-07T07:38:57.107378Z","iopub.execute_input":"2021-07-07T07:38:57.107901Z","iopub.status.idle":"2021-07-07T07:38:57.688566Z","shell.execute_reply.started":"2021-07-07T07:38:57.107864Z","shell.execute_reply":"2021-07-07T07:38:57.687784Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["\n","import pandas as pd\n","test = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")\n","dnn = DNN(backbone='conv', \n","            charlevel=False,\n","            use_glove=True,\n","            preprocess_data=False,\n","            logger=None,\n","            batch_size=64,\n","            max_vocab=10000,\n","            max_len=8192,\n","            embedding_mat_columns=50,\n","            epochs=200)\n","\n","dnn.load('../input/d/pilarpieiro/dnn-modelv1')\n","preds = dnn.predict(test[\"excerpt\"], return_proba=True)\n","predictions = preds.squeeze(-1)\n","submission = pd.DataFrame({'id': test.id, 'target':predictions })\n","submission.to_csv('/kaggle/working/submission.csv', index=False)"],"metadata":{"execution":{"iopub.status.busy":"2021-07-07T07:38:57.689981Z","iopub.execute_input":"2021-07-07T07:38:57.690307Z","iopub.status.idle":"2021-07-07T07:43:24.288976Z","shell.execute_reply.started":"2021-07-07T07:38:57.690273Z","shell.execute_reply":"2021-07-07T07:43:24.288043Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Loading model...\nLoading tokenizer\nReading...\nModel from yaml\nLoading weights\nDone\n=====================\n0    My hope lay in Jack's promise that he would ke...\n1    Dotty continued to go to Mrs. Gray's every nig...\n2    It was a bright and cheerful scene that greete...\n3    Cell division is the process by which a parent...\n4    Debugging is the process of finding and resolv...\n5    To explain transitivity, let us look first at ...\n6    Milka and John are playing in the garden. Her ...\nName: excerpt, dtype: object\n[[-0.94771826]\n [-0.779474  ]\n [-0.39480895]\n [-1.4428356 ]\n [-1.7663398 ]\n [-1.3449428 ]\n [-0.79534453]]\n","output_type":"stream"}]}]}